{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-task Tweet Classification Using BERTModel.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1YB8wqacQooQWBCrbZRI0w4Q7zmPUz2PB",
      "authorship_tag": "ABX9TyNN0OSLbqih9/Cie43aH9OD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a893e6bd47a4122a8219665fc3e1fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_02daf33311864fb99872b08abbacb07c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b076f7e94bbf4be78b6abc37dac52495",
              "IPY_MODEL_9a0d348a4ad94e9b8f0703240e7f8f14"
            ]
          }
        },
        "02daf33311864fb99872b08abbacb07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b076f7e94bbf4be78b6abc37dac52495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82192732d4c647b5921458ea7c4c5119",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e6ef7973dbc443e973190254c3cf896"
          }
        },
        "9a0d348a4ad94e9b8f0703240e7f8f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_782cef8aef5645899b4f99961cb5621f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 726kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c79afbe8b934115a90f40d1d3a0e080"
          }
        },
        "82192732d4c647b5921458ea7c4c5119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e6ef7973dbc443e973190254c3cf896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "782cef8aef5645899b4f99961cb5621f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c79afbe8b934115a90f40d1d3a0e080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauraosede/Mullti-task-Tweet-Classification-Using-BERT-Model/blob/Datasets/%5CcolabCode%5CMulti_task_Tweet_Classification_Using_BERTModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTvfNImA7HEB"
      },
      "source": [
        "##1) Import Libraries\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt7xqzq-1f7T",
        "outputId": "50a95070-f197-474e-fcc4-ea410a2b37ee"
      },
      "source": [
        "!pip install transformers\r\n",
        "\r\n",
        "\r\n",
        "#imports \r\n",
        "import os\r\n",
        "import pandas as pd # for data manipulation and analysis\r\n",
        "import numpy as np # for working with arrays and carrying out mathematical operations. Pandas is built on Numpy\r\n",
        "import csv # to read and write csv files\r\n",
        "import re # In-built regular expressions library\r\n",
        "import string # Inbuilt string library\r\n",
        "import glob # to retrieve files/pathnames matching a specified pattern. \r\n",
        "import random # generating random numbers\r\n",
        "import requests # to send HTTP requests\r\n",
        "from PIL import Image # for opening, manipulating, and saving many different image file f\r\n",
        "import matplotlib.pyplot as plt # for plotting\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('words')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "\r\n",
        "from transformers import BertTokenizer, BertModel, BertConfig,  BertForPreTraining\r\n",
        "import torch\r\n",
        "from transformers import AutoModelForSequenceClassification\r\n",
        "from transformers import TFAutoModelForSequenceClassification\r\n",
        "from transformers import AutoTokenizer\r\n",
        "from scipy.special import softmax\r\n",
        "import urllib.request\r\n",
        "\r\n",
        "# Natural Language Processing Toolkit\r\n",
        "from nltk.corpus import stopwords, words # get stopwords from NLTK library & get all words in english language\r\n",
        "from nltk.tokenize import word_tokenize # to create word tokens\r\n",
        "# from nltk.stem import PorterStemmer (I played around with Stemmer and decided to use Lemmatizer instead)\r\n",
        "from nltk.stem import WordNetLemmatizer # to reduce words to orginal form\r\n",
        "from nltk import pos_tag # For Parts of Speech tagging\r\n",
        "\r\n",
        "from textblob import TextBlob # TextBlob - Python library for processing textual data\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# WordCloud - Python linrary for creating image wordclouds\r\n",
        "from wordcloud import WordCloud\r\n",
        "\r\n",
        "!pip install emot\r\n",
        "from emot.emo_unicode import UNICODE_EMO, EMOTICONS # For emojis\r\n",
        "\r\n",
        "def extract_emojis(s):\r\n",
        "  return ''.join(c for c in s if c in emoji.UNICODE_EMOJI)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "Requirement already satisfied: emot in /usr/local/lib/python3.7/dist-packages (2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwf2O7NR8gfq"
      },
      "source": [
        "##2) Data Cleaning and Preparation for EDA\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K2ZhMuV8X_I"
      },
      "source": [
        "Before performing exploratory data analysis, we need to clean and prepare our data as much as possible. Tasks here will include;\r\n",
        "*   Examining our data\r\n",
        "*   Removing null values or performing imputation from our dataset\r\n",
        "*   Expand contractions\r\n",
        "*   Lowercase the tweets\r\n",
        "*   Remove punctuations\r\n",
        "*   Lemmatize tweet - reduces the inflectional forms of each word into a common base or root.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUPceNli5vwI"
      },
      "source": [
        "#####Defining functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OJpmXkn8tWs"
      },
      "source": [
        "#function reads two txt files, converts it to dataframe and returns dataframe\r\n",
        "def read_file(filename1, filename2): \r\n",
        "    train_line = []\r\n",
        "    train_label = []\r\n",
        "\r\n",
        "    #opening text file\r\n",
        "    with open(filename1, 'r') as reader:\r\n",
        "        lines = reader.readlines()\r\n",
        "        for line in lines:\r\n",
        "            train_line.append(line.rstrip())\r\n",
        "    \r\n",
        "    #opening train file \r\n",
        "    with open(filename2, 'r') as reader:\r\n",
        "      label_lines = reader.readlines()\r\n",
        "      for line in label_lines:\r\n",
        "        train_label.append(line.rstrip())\r\n",
        "    \r\n",
        "\r\n",
        "    #convert text file to data frame\r\n",
        "    df = pd.DataFrame()\r\n",
        "    df['text'] = train_line\r\n",
        "    df['Mapping'] = train_label\r\n",
        "    return df\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjrKeCXumO8H"
      },
      "source": [
        "#function removes '@',  http links, punctuations, emojis, and stop words from data\r\n",
        "def preprocess(tweet): \r\n",
        "    tweet = tweet.lower()  #has to be in place\r\n",
        "    # Remove urls\r\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\r\n",
        "    # Remove user @ references and '#' from tweet\r\n",
        "    tweet = re.sub(r'\\@\\w+|\\#|\\d+', '', tweet)\r\n",
        "    \r\n",
        "    # convert string to tokens\r\n",
        "    PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\r\n",
        "    tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n",
        "    tokens = tokenizer.tokenize(tweet) \r\n",
        "\r\n",
        "    # Remove stopwords\r\n",
        "    filtered_words = [w for w in tokens if w not in stop_words]\r\n",
        "    filtered_words = [w for w in filtered_words if w not in emojis]\r\n",
        "    filtered_words = [w for w in filtered_words if w in word_list]\r\n",
        "\r\n",
        "    # Remove punctuations\r\n",
        "    unpunctuated_words = [char for char in filtered_words if char not in string.punctuation]\r\n",
        "    unpunctuated_words = ' '.join(unpunctuated_words)\r\n",
        "\r\n",
        "    return \"\".join(unpunctuated_words)  # join words with a space in between them"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SnRBY_q_1ut"
      },
      "source": [
        "# function to return words to their base form using Lemmatizer\r\n",
        "def preprocessTweetsSentiments(tweet):\r\n",
        "    tweet_tokens = word_tokenize(tweet)\r\n",
        "    lemmatizer = WordNetLemmatizer() # instatiate an object WordNetLemmatizer Class\r\n",
        "    lemma_words = [lemmatizer.lemmatize(w) for w in tweet_tokens]\r\n",
        "    return \" \".join(lemma_words)\r\n",
        "\r\n",
        "    \r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WArHTkJCDfA"
      },
      "source": [
        "# function to obtain adjectives from tweets\r\n",
        "def getAdjectives(tweet):\r\n",
        "    tweet = word_tokenize(tweet)  # convert string to tokens\r\n",
        "    tweet = [word for (word, tag) in pos_tag(tweet)\r\n",
        "             if tag == \"JJ\"]  # pos_tag module in NLTK library\r\n",
        "    return \" \".join(tweet)  # join words with a space in between them"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVCQUVaowXms"
      },
      "source": [
        "# Defining my NLTK stop words\r\n",
        "stop_words = list(stopwords.words('english'))\r\n",
        "alphabets = list(string.ascii_lowercase)\r\n",
        "stop_words = stop_words + alphabets\r\n",
        "word_list = words.words()  # all words in English language\r\n",
        "emojis = list(UNICODE_EMO.keys())  # full list of emojis"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOfzn0DHCEjx"
      },
      "source": [
        "#####Exploring emotion dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7U6d1itASdP"
      },
      "source": [
        "emotion_train = read_file('/content/drive/MyDrive/datasets/emotions/train_text.txt','/content/drive/MyDrive/datasets/emotions/train_labels.txt' )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0qEPvqvOjqi"
      },
      "source": [
        "Examining our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQqS3arDAKOH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "2415ea97-b09b-4e25-d7ed-23d3c289a9b9"
      },
      "source": [
        "emotion_train.head(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Mapping</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‚ÄúWorry is a down payment on a problem you may ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@user but your pussy was weak from what I hear...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Making that yearly transition from excited and...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Tiller and breezy should do a collab album. Ra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@user broadband is shocking regretting signing...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@user Look at those teef! #growl</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text Mapping\n",
              "0  ‚ÄúWorry is a down payment on a problem you may ...       2\n",
              "1  My roommate: it's okay that we can't spell bec...       0\n",
              "2  No but that's so cute. Atsu was probably shy a...       1\n",
              "3  Rooneys fucking untouchable isn't he? Been fuc...       0\n",
              "4  it's pretty depressing when u hit pan on ur fa...       3\n",
              "5  @user but your pussy was weak from what I hear...       0\n",
              "6  Making that yearly transition from excited and...       3\n",
              "7  Tiller and breezy should do a collab album. Ra...       1\n",
              "8  @user broadband is shocking regretting signing...       0\n",
              "9                   @user Look at those teef! #growl       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHdpaBxTJj_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a93fe9ac-f749-43b2-9fe7-295d863c1841"
      },
      "source": [
        "emotion_train.describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Mapping</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3257</td>\n",
              "      <td>3257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3232</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Watch this amazing live.ly broadcast by @user ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>15</td>\n",
              "      <td>1400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text Mapping\n",
              "count                                                3257    3257\n",
              "unique                                               3232       4\n",
              "top     Watch this amazing live.ly broadcast by @user ...       0\n",
              "freq                                                   15    1400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64qiRR9pPnZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a69b9d-c2d9-4bac-81cd-972d184e3a6f"
      },
      "source": [
        "emotion_train.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3257 entries, 0 to 3256\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   text     3257 non-null   object\n",
            " 1   Mapping  3257 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 51.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld6eT-r5PD0S"
      },
      "source": [
        "We want to examin the tweets indept, so we print the first 40 tweets out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-4pandFMD8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81bcb22b-1461-4db0-a697-0f0cbc78c3c3"
      },
      "source": [
        "for index,text in enumerate(emotion_train['text'][0:40]): \r\n",
        "  print((index+1),text)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 ‚ÄúWorry is a down payment on a problem you may never have'. ¬†Joyce Meyer.  #motivation #leadership #worry\n",
            "2 My roommate: it's okay that we can't spell because we have autocorrect. #terrible #firstworldprobs\n",
            "3 No but that's so cute. Atsu was probably shy about photos before but cherry helped her out uwu\n",
            "4 Rooneys fucking untouchable isn't he? Been fucking dreadful again, depay has looked decent(ish)tonight\n",
            "5 it's pretty depressing when u hit pan on ur favourite highlighter\n",
            "6 @user but your pussy was weak from what I heard so stfu up to me bitch . You got to threaten him that your pregnant .\n",
            "7 Making that yearly transition from excited and hopeful college returner to sick and exhausted pessimist. #college\n",
            "8 Tiller and breezy should do a collab album. Rapping and singing prolly be fire\n",
            "9 @user broadband is shocking regretting signing up now #angry #shouldofgonewithvirgin\n",
            "10 @user Look at those teef! #growl\n",
            "11 @user @user USA was embarrassing to watch. When was the last time you guys won a game..? #horrible #joke\n",
            "12 #NewYork: Several #Baloch &amp; Indian activists hold demonstrations outside @user headquarters demanding Pak to stop exporting #terror into India\n",
            "13 Your glee filled Normy dry humping of the most recent high profile celebrity break up is pathetic &amp; all that is wrong with the world today.\n",
            "14 What a fucking muppet.  @user  #stalker.\n",
            "15 Autocorrect changes ''em' to 'me' which I resent greatly\n",
            "16 @user I would never strategically vote for someone I don't agree with. A lot of the Clinton vote based on fear and negativity.\n",
            "17 @user Haters!!! You are low in self worth. Self righteous in your delusions. You cower at the thought of change. Change is inevitable.\n",
            "18 I saved him after ordering him to risk his life. I didn't panic but stayed calm and rescued him.\n",
            "19 @user Uggh that's really horrible. You're not a bad person by any stretch of the imagination. I hope this person realizes that.\n",
            "20 @user @user @user Tamra would F her up if she swung on Tamra\\nKelly is a piece of üí© #needstobeadmitted #bully\n",
            "21 Love is when all your happiness and all your sadness and all your feelings are dependent on another person.\n",
            "22 It‚Äôs possible changing meds is best not done while under stress. Difficult to tell what part of despair is circumstantial, what is drugs.\n",
            "23 im also definitely still bitter about the yellow ranger not being asian, but asian representation in hollywood is essentially a shrug anyway\n",
            "24 @user The irony is that those protesting about this kind of stuff are the Orwellian nightmare they think they‚Äôre fighting against.\n",
            "25 @user @user nah way that's horrible\n",
            "26 @user I think just becz u have so much terror in pak nd urself being  a leader u forgot d difference btw a leader nd terrorist !\n",
            "27 angel delight is my everything\n",
            "28 Puzzle investing opening portland feodal population is correlative straight a snorting infuriate: XLzjYhG\n",
            "29 I believe I'm gonna start singing in my snap stories on the tractor. Switch it up a little bit.\n",
            "30 I have a rage rage ep 2 coming out soon I'll keep you posted on it #YouTube #youtubegaming #rage\n",
            "31 Why have I only just started watching glee this week I am now addicted üôÑ #glee #GLEEK\n",
            "32 Jorge deserves it, honestly. He's weak.  #90dayfiance\n",
            "33 @user 'shit' doesn't even begin to describe these fiery little demons straight from hell üåùüåö ;)\n",
            "34 @user @user ditto!! Such an amazing atmosphere! #PhilippPlein #cheerleaders #stunt #LondonEvents #cheer\n",
            "35 Interview preparation, I hate talking about myself, one dull subject matter! #yawnoff\n",
            "36 Manchester derby at home\n",
            "37 It'd probably be useful to more than women, but I'm dealing with re-reading an article about a woman being harassed on the subway. #concern\n",
            "38 her; i want a playful relationship\\nme; *kicks her off the couch*\n",
            "39 Romero is fucking dreadful like seriously my 11 month old is better than him.\n",
            "40 @user It‚Äôs taken for granted, while the misogyny in the air is treated as normal ‚Äî and any angry response to it as pathological.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_222bCiN5-j"
      },
      "source": [
        "From this data, it is obvious that there are contractions, emoticons, hashtags, puntuation marks like; '',*, @ \\n , !,etc. we will use our functions created to clean the data a little so as to achieve better accuracy\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSdtNs0ZiUeL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6a893e6bd47a4122a8219665fc3e1fb6",
            "02daf33311864fb99872b08abbacb07c",
            "b076f7e94bbf4be78b6abc37dac52495",
            "9a0d348a4ad94e9b8f0703240e7f8f14",
            "82192732d4c647b5921458ea7c4c5119",
            "8e6ef7973dbc443e973190254c3cf896",
            "782cef8aef5645899b4f99961cb5621f",
            "1c79afbe8b934115a90f40d1d3a0e080"
          ]
        },
        "outputId": "ef4b4595-a71e-4c7d-944e-519777c96821"
      },
      "source": [
        "# Apply preprocess function to the 'text' column to generate a new column called 'Processed text'.\r\n",
        "emotion_train['Processed_Text'] = emotion_train['text'].apply(preprocess)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a893e6bd47a4122a8219665fc3e1fb6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AcQ5mtQCKaI"
      },
      "source": [
        "# Apply getAdjectives function to the new 'Processed Tweets' column to generate a new column called 'Tweets_Adjectives'\r\n",
        "emotion_train['Text_Adjectives'] = emotion_train['Processed_Text'].apply(getAdjectives)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGeNqcSRA1Hd"
      },
      "source": [
        "# Apply preprocessTweetsSentiments function to the 'Processed Tweets' column to generate a new column\r\n",
        "# called 'Processed_Tweets'\r\n",
        "emotion_train['Text_Sentiments'] = emotion_train['Processed_Text'].apply(preprocessTweetsSentiments)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPtb3ilfm6SK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee500fc2-a5bd-45ee-c44c-0af01f5ef777"
      },
      "source": [
        "emotion_train.head(40)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Mapping</th>\n",
              "      <th>Processed_Text</th>\n",
              "      <th>Text_Adjectives</th>\n",
              "      <th>Text_Sentiments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‚ÄúWorry is a down payment on a problem you may ...</td>\n",
              "      <td>2</td>\n",
              "      <td>worry payment problem may never joy motivation...</td>\n",
              "      <td>worry</td>\n",
              "      <td>worry payment problem may never joy motivation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
              "      <td>0</td>\n",
              "      <td>roommate spell auto terrible first</td>\n",
              "      <td>terrible first</td>\n",
              "      <td>roommate spell auto terrible first</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
              "      <td>1</td>\n",
              "      <td>cute probably shy cherry</td>\n",
              "      <td>shy</td>\n",
              "      <td>cute probably shy cherry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
              "      <td>0</td>\n",
              "      <td>unto dreadful de decent tonight</td>\n",
              "      <td>unto</td>\n",
              "      <td>unto dreadful de decent tonight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
              "      <td>3</td>\n",
              "      <td>pretty de hit pan highlight</td>\n",
              "      <td></td>\n",
              "      <td>pretty de hit pan highlight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@user but your pussy was weak from what I hear...</td>\n",
              "      <td>0</td>\n",
              "      <td>pu weak bitch got threaten pregnant</td>\n",
              "      <td>weak threaten pregnant</td>\n",
              "      <td>pu weak bitch got threaten pregnant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Making that yearly transition from excited and...</td>\n",
              "      <td>3</td>\n",
              "      <td>making yearly transition excited hopeful colle...</td>\n",
              "      <td>yearly hopeful sick</td>\n",
              "      <td>making yearly transition excited hopeful colle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Tiller and breezy should do a collab album. Ra...</td>\n",
              "      <td>1</td>\n",
              "      <td>till album rap singing pro fire</td>\n",
              "      <td>pro</td>\n",
              "      <td>till album rap singing pro fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@user broadband is shocking regretting signing...</td>\n",
              "      <td>0</td>\n",
              "      <td>shocking regret angry</td>\n",
              "      <td>angry</td>\n",
              "      <td>shocking regret angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@user Look at those teef! #growl</td>\n",
              "      <td>0</td>\n",
              "      <td>look tee growl</td>\n",
              "      <td></td>\n",
              "      <td>look tee growl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>@user @user USA was embarrassing to watch. Whe...</td>\n",
              "      <td>0</td>\n",
              "      <td>us embarrassing watch last time game horrible ...</td>\n",
              "      <td>last horrible</td>\n",
              "      <td>u embarrassing watch last time game horrible joke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>#NewYork: Several #Baloch &amp;amp; Indian activis...</td>\n",
              "      <td>3</td>\n",
              "      <td>new several hold outside headquarters demandin...</td>\n",
              "      <td>new several outside stop</td>\n",
              "      <td>new several hold outside headquarters demandin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Your glee filled Normy dry humping of the most...</td>\n",
              "      <td>0</td>\n",
              "      <td>filled norm dry hum recent high profile celebr...</td>\n",
              "      <td>dry recent high pathetic wrong</td>\n",
              "      <td>filled norm dry hum recent high profile celebr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What a fucking muppet.  @user  #stalker.</td>\n",
              "      <td>0</td>\n",
              "      <td>stalk</td>\n",
              "      <td></td>\n",
              "      <td>stalk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Autocorrect changes ''em' to 'me' which I rese...</td>\n",
              "      <td>0</td>\n",
              "      <td>auto em greatly</td>\n",
              "      <td></td>\n",
              "      <td>auto em greatly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>@user I would never strategically vote for som...</td>\n",
              "      <td>0</td>\n",
              "      <td>would never strategically vote someone agree l...</td>\n",
              "      <td>agree</td>\n",
              "      <td>would never strategically vote someone agree l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>@user Haters!!! You are low in self worth. Sel...</td>\n",
              "      <td>0</td>\n",
              "      <td>hate low self worth self right cow thought cha...</td>\n",
              "      <td>low right inevitable</td>\n",
              "      <td>hate low self worth self right cow thought cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>I saved him after ordering him to risk his lif...</td>\n",
              "      <td>2</td>\n",
              "      <td>saved risk life panic stayed calm</td>\n",
              "      <td>panic</td>\n",
              "      <td>saved risk life panic stayed calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>@user Uggh that's really horrible. You're not ...</td>\n",
              "      <td>2</td>\n",
              "      <td>really horrible bad person stretch imagination...</td>\n",
              "      <td>horrible bad</td>\n",
              "      <td>really horrible bad person stretch imagination...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>@user @user @user Tamra would F her up if she ...</td>\n",
              "      <td>0</td>\n",
              "      <td>ta would swung ta piece needs bull</td>\n",
              "      <td>ta</td>\n",
              "      <td>ta would swung ta piece need bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Love is when all your happiness and all your s...</td>\n",
              "      <td>2</td>\n",
              "      <td>love happiness sadness dependent another person</td>\n",
              "      <td></td>\n",
              "      <td>love happiness sadness dependent another person</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>It‚Äôs possible changing meds is best not done w...</td>\n",
              "      <td>3</td>\n",
              "      <td>possible best done stress difficult tell part ...</td>\n",
              "      <td>possible difficult</td>\n",
              "      <td>possible best done stress difficult tell part ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>im also definitely still bitter about the yell...</td>\n",
              "      <td>0</td>\n",
              "      <td>also definitely still bitter yellow range repr...</td>\n",
              "      <td>bitter yellow shrug</td>\n",
              "      <td>also definitely still bitter yellow range repr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>@user The irony is that those protesting about...</td>\n",
              "      <td>0</td>\n",
              "      <td>irony kind stuff nightmare think fighting</td>\n",
              "      <td></td>\n",
              "      <td>irony kind stuff nightmare think fighting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>@user @user nah way that's horrible</td>\n",
              "      <td>0</td>\n",
              "      <td>na way horrible</td>\n",
              "      <td>horrible</td>\n",
              "      <td>na way horrible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>@user I think just becz u have so much terror ...</td>\n",
              "      <td>0</td>\n",
              "      <td>think much terror leader forgot difference lea...</td>\n",
              "      <td>much</td>\n",
              "      <td>think much terror leader forgot difference lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>angel delight is my everything</td>\n",
              "      <td>1</td>\n",
              "      <td>angel delight everything</td>\n",
              "      <td></td>\n",
              "      <td>angel delight everything</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Puzzle investing opening portland feodal popul...</td>\n",
              "      <td>0</td>\n",
              "      <td>puzzle opening port population straight</td>\n",
              "      <td>port</td>\n",
              "      <td>puzzle opening port population straight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>I believe I'm gonna start singing in my snap s...</td>\n",
              "      <td>1</td>\n",
              "      <td>believe start singing snap tractor switch litt...</td>\n",
              "      <td>snap little</td>\n",
              "      <td>believe start singing snap tractor switch litt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>I have a rage rage ep 2 coming out soon I'll k...</td>\n",
              "      <td>0</td>\n",
              "      <td>rage rage coming soon keep posted rage</td>\n",
              "      <td></td>\n",
              "      <td>rage rage coming soon keep posted rage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Why have I only just started watching glee thi...</td>\n",
              "      <td>1</td>\n",
              "      <td>watching week add</td>\n",
              "      <td></td>\n",
              "      <td>watching week add</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Jorge deserves it, honestly. He's weak.  #90da...</td>\n",
              "      <td>0</td>\n",
              "      <td>honestly weak day</td>\n",
              "      <td>weak</td>\n",
              "      <td>honestly weak day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>@user 'shit' doesn't even begin to describe th...</td>\n",
              "      <td>0</td>\n",
              "      <td>even begin describe fiery little straight hell</td>\n",
              "      <td>fiery little</td>\n",
              "      <td>even begin describe fiery little straight hell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>@user @user ditto!! Such an amazing atmosphere...</td>\n",
              "      <td>1</td>\n",
              "      <td>di amazing atmosphere cheer stunt lo cheer</td>\n",
              "      <td></td>\n",
              "      <td>di amazing atmosphere cheer stunt lo cheer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Interview preparation, I hate talking about my...</td>\n",
              "      <td>0</td>\n",
              "      <td>interview preparation hate talking one dull su...</td>\n",
              "      <td>subject</td>\n",
              "      <td>interview preparation hate talking one dull su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Manchester derby at home</td>\n",
              "      <td>1</td>\n",
              "      <td>man derby home</td>\n",
              "      <td></td>\n",
              "      <td>man derby home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>It'd probably be useful to more than women, bu...</td>\n",
              "      <td>0</td>\n",
              "      <td>probably useful dealing reading article woman ...</td>\n",
              "      <td>useful</td>\n",
              "      <td>probably useful dealing reading article woman ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>her; i want a playful relationship\\nme; *kicks...</td>\n",
              "      <td>1</td>\n",
              "      <td>want playful relationship couch</td>\n",
              "      <td>want</td>\n",
              "      <td>want playful relationship couch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Romero is fucking dreadful like seriously my 1...</td>\n",
              "      <td>0</td>\n",
              "      <td>dreadful like seriously month old better</td>\n",
              "      <td>old</td>\n",
              "      <td>dreadful like seriously month old better</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>@user It‚Äôs taken for granted, while the misogy...</td>\n",
              "      <td>0</td>\n",
              "      <td>taken mi air normal angry response path</td>\n",
              "      <td>normal angry</td>\n",
              "      <td>taken mi air normal angry response path</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ...                                    Text_Sentiments\n",
              "0   ‚ÄúWorry is a down payment on a problem you may ...  ...  worry payment problem may never joy motivation...\n",
              "1   My roommate: it's okay that we can't spell bec...  ...                 roommate spell auto terrible first\n",
              "2   No but that's so cute. Atsu was probably shy a...  ...                           cute probably shy cherry\n",
              "3   Rooneys fucking untouchable isn't he? Been fuc...  ...                    unto dreadful de decent tonight\n",
              "4   it's pretty depressing when u hit pan on ur fa...  ...                        pretty de hit pan highlight\n",
              "5   @user but your pussy was weak from what I hear...  ...                pu weak bitch got threaten pregnant\n",
              "6   Making that yearly transition from excited and...  ...  making yearly transition excited hopeful colle...\n",
              "7   Tiller and breezy should do a collab album. Ra...  ...                    till album rap singing pro fire\n",
              "8   @user broadband is shocking regretting signing...  ...                              shocking regret angry\n",
              "9                    @user Look at those teef! #growl  ...                                     look tee growl\n",
              "10  @user @user USA was embarrassing to watch. Whe...  ...  u embarrassing watch last time game horrible joke\n",
              "11  #NewYork: Several #Baloch &amp; Indian activis...  ...  new several hold outside headquarters demandin...\n",
              "12  Your glee filled Normy dry humping of the most...  ...  filled norm dry hum recent high profile celebr...\n",
              "13           What a fucking muppet.  @user  #stalker.  ...                                              stalk\n",
              "14  Autocorrect changes ''em' to 'me' which I rese...  ...                                    auto em greatly\n",
              "15  @user I would never strategically vote for som...  ...  would never strategically vote someone agree l...\n",
              "16  @user Haters!!! You are low in self worth. Sel...  ...  hate low self worth self right cow thought cha...\n",
              "17  I saved him after ordering him to risk his lif...  ...                  saved risk life panic stayed calm\n",
              "18  @user Uggh that's really horrible. You're not ...  ...  really horrible bad person stretch imagination...\n",
              "19  @user @user @user Tamra would F her up if she ...  ...                  ta would swung ta piece need bull\n",
              "20  Love is when all your happiness and all your s...  ...    love happiness sadness dependent another person\n",
              "21  It‚Äôs possible changing meds is best not done w...  ...  possible best done stress difficult tell part ...\n",
              "22  im also definitely still bitter about the yell...  ...  also definitely still bitter yellow range repr...\n",
              "23  @user The irony is that those protesting about...  ...          irony kind stuff nightmare think fighting\n",
              "24                @user @user nah way that's horrible  ...                                    na way horrible\n",
              "25  @user I think just becz u have so much terror ...  ...  think much terror leader forgot difference lea...\n",
              "26                     angel delight is my everything  ...                           angel delight everything\n",
              "27  Puzzle investing opening portland feodal popul...  ...            puzzle opening port population straight\n",
              "28  I believe I'm gonna start singing in my snap s...  ...  believe start singing snap tractor switch litt...\n",
              "29  I have a rage rage ep 2 coming out soon I'll k...  ...             rage rage coming soon keep posted rage\n",
              "30  Why have I only just started watching glee thi...  ...                                  watching week add\n",
              "31  Jorge deserves it, honestly. He's weak.  #90da...  ...                                  honestly weak day\n",
              "32  @user 'shit' doesn't even begin to describe th...  ...     even begin describe fiery little straight hell\n",
              "33  @user @user ditto!! Such an amazing atmosphere...  ...         di amazing atmosphere cheer stunt lo cheer\n",
              "34  Interview preparation, I hate talking about my...  ...  interview preparation hate talking one dull su...\n",
              "35                           Manchester derby at home  ...                                     man derby home\n",
              "36  It'd probably be useful to more than women, bu...  ...  probably useful dealing reading article woman ...\n",
              "37  her; i want a playful relationship\\nme; *kicks...  ...                    want playful relationship couch\n",
              "38  Romero is fucking dreadful like seriously my 1...  ...           dreadful like seriously month old better\n",
              "39  @user It‚Äôs taken for granted, while the misogy...  ...            taken mi air normal angry response path\n",
              "\n",
              "[40 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzftVsk9qCm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26955e05-0c3d-422b-8760-e400f11ca8b7"
      },
      "source": [
        "#printing results for better analysis\r\n",
        "print(emotion_train['text'][19])\r\n",
        "print(emotion_train['Processed_Text'][19])\r\n",
        "print(emotion_train['Text_Sentiments'][19])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@user @user @user Tamra would F her up if she swung on Tamra\\nKelly is a piece of üí© #needstobeadmitted #bully\n",
            "ta would swung ta piece needs bull\n",
            "ta would swung ta piece need bull\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itr4CIR1Cyap"
      },
      "source": [
        "#####Exploring irony dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wow4QbIAC1ng"
      },
      "source": [
        "irony_train = read_file('/content/drive/MyDrive/datasets/irony/train_text.txt', '/content/drive/MyDrive/datasets/irony/train_labels.txt')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH7vx2ZXDJLQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "1f7a592b-bfed-4489-ccf1-5a36d3d3870a"
      },
      "source": [
        "irony_train.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Mapping</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>seeing ppl walking w/ crutches makes me really...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>look for the girl with the broken smile, ask h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Now I remember why I buy books online @user #s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user @user So is he banded from wearing the c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just found out there are Etch A Sketch apps.  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text Mapping\n",
              "0  seeing ppl walking w/ crutches makes me really...       1\n",
              "1  look for the girl with the broken smile, ask h...       0\n",
              "2  Now I remember why I buy books online @user #s...       1\n",
              "3  @user @user So is he banded from wearing the c...       1\n",
              "4  Just found out there are Etch A Sketch apps.  ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwyRnkohJLjy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "cde49ff8-39aa-40ca-a744-caae48a3ee52"
      },
      "source": [
        "irony_train.describe()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Mapping</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2862</td>\n",
              "      <td>2862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2862</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>8.30am conference calls.|#love</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1445</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  text Mapping\n",
              "count                             2862    2862\n",
              "unique                            2862       2\n",
              "top     8.30am conference calls.|#love       1\n",
              "freq                                 1    1445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLNaLDOpJfSJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "159aecd1-e091-43f6-8178-78352709ec14"
      },
      "source": [
        "irony_train['Mapping'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4240500c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnotx1T3Czcn"
      },
      "source": [
        "Repeating the preprocessing steps I took earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFvtlmrxC-fm"
      },
      "source": [
        "# Apply preprocess function to the 'text' column to generate a new column called 'Processed text'.\r\n",
        "irony_train['Processed_Text'] = irony_train['text'].apply(preprocess)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWANPdGwFFUu"
      },
      "source": [
        "# Apply getAdjectives function to the new 'Processed Tweets' column to generate a new column called 'Tweets_Adjectives'\r\n",
        "irony_train['Text_Adjectives'] = irony_train['Processed_Text'].apply(getAdjectives)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW5vLTG9FNEj"
      },
      "source": [
        "# Apply preprocessTweetsSentiments function to the 'Processed Tweets' column to generate a new column\r\n",
        "# called 'Processed_Tweets'\r\n",
        "irony_train['Text_Sentiments'] = irony_train['Processed_Text'].apply(preprocessTweetsSentiments)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLz2gBLwFsyt",
        "outputId": "42324f69-225b-49cf-bf19-3869469ca667"
      },
      "source": [
        "#printing results for better analysis\r\n",
        "print(irony_train['text'][19])\r\n",
        "print(irony_train['Processed_Text'][19])\r\n",
        "print(irony_train['Text_Sentiments'][19])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Main issue with the walking dead- you forget to breathe when you're watching. So bloody good #WalkingDead\n",
            "main issue walking dead forget breathe watching bloody good walking\n",
            "main issue walking dead forget breathe watching bloody good walking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDLhoSpDNQR"
      },
      "source": [
        "#####Exploring sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtE-DSDhDano"
      },
      "source": [
        "sentiment_train = read_file('/content/drive/MyDrive/datasets/sentiment/train_text.txt','/content/drive/MyDrive/datasets/sentiment/train_labels.txt')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_l9s2ukDhaQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "c87f2615-5315-4837-d49c-1fe49238b88e"
      },
      "source": [
        "sentiment_train.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Mapping</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"QT @user In the original draft of the 7th boo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Ben Smith / Smith (concussion) remains out of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sorry bout the stream last night I crashed out...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chase Headley's RBI double in the 8th inning o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user Alciato: Bee will invest 150 million in ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text Mapping\n",
              "0  \"QT @user In the original draft of the 7th boo...       2\n",
              "1  \"Ben Smith / Smith (concussion) remains out of...       1\n",
              "2  Sorry bout the stream last night I crashed out...       1\n",
              "3  Chase Headley's RBI double in the 8th inning o...       1\n",
              "4  @user Alciato: Bee will invest 150 million in ...       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_A3WLptJOvx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "24705233-a270-449c-eac3-27d77fb29c6f"
      },
      "source": [
        "sentiment_train.describe()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Mapping</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45615</td>\n",
              "      <td>45615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>45586</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Cycling Mission with Passion Team #Ride2Light ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>3</td>\n",
              "      <td>20673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text Mapping\n",
              "count                                               45615   45615\n",
              "unique                                              45586       3\n",
              "top     Cycling Mission with Passion Team #Ride2Light ...       1\n",
              "freq                                                    3   20673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL_XXJC1JWXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "14382ec3-8aa4-4e5a-b878-401c7bfe7683"
      },
      "source": [
        "sentiment_train['Mapping'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f423f9f0510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD1CAYAAACyaJl6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAS5UlEQVR4nO3df4xd5X3n8fenpkRRsxGmzFqOf9RuOrQCdtcJI0LVpmKXDRhS1aSqWKNV7GZRnCiw20iVNk77B1GyrNzdptGizdJ1NhamSiE0NMVKnLiulW1U7Zp4SCyDIdQDMctYxp5iNjRNRWvy3T/uM9uTYcYez52Za+L3S7q653yf55zzXF3JH5/nnDsnVYUk6cL2Y4MegCRp8AwDSZJhIEkyDCRJGAaSJAwDSRJw0aAHMFeXXXZZrVmzZtDDkKTXlccee+yvqmpoav11GwZr1qxhdHR00MOQpNeVJM9NV3eaSJJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJJ4Hf/obLGt2frlQQ9hQR3d9u5BD0HSAHlmIEkyDCRJswiDJKuSfC3Jk0kOJ/mNVr80yd4kR9r70lZPknuSjCU5lOTtnX1tbv2PJNncqV+d5PG2zT1JshAfVpI0vdmcGZwGfrOqrgCuBe5IcgWwFdhXVcPAvrYOcBMw3F5bgHuhFx7AXcA7gGuAuyYDpPV5f2e79f1/NEnSbJ01DKrqeFV9sy3/NfAUsALYAOxs3XYCt7TlDcD91bMfuCTJcuBGYG9Vnaqql4C9wPrW9uaq2l9VBdzf2ZckaRGc0zWDJGuAtwGPAsuq6nhregFY1pZXAM93NhtvtTPVx6epS5IWyazDIMmbgIeBD1fVy9229j/6muexTTeGLUlGk4xOTEws9OEk6YIxqzBI8uP0guBzVfXHrXyiTfHQ3k+2+jFgVWfzla12pvrKaeqvUVXbq2qkqkaGhl7zoB5J0hzN5m6iAJ8Fnqqq3+s07QIm7wjaDDzSqW9qdxVdC3y3TSftAW5IsrRdOL4B2NPaXk5ybTvWps6+JEmLYDa/QP4F4L3A40kOttpvAduAh5LcDjwH3NradgM3A2PA94H3AVTVqSSfAA60fh+vqlNt+UPAfcAbga+0lyRpkZw1DKrqL4CZ7vu/fpr+Bdwxw752ADumqY8CV51tLJKkheEvkCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkidk99nJHkpNJnujUPp/kYHsdnXwCWpI1Sf620/b7nW2uTvJ4krEk97RHXJLk0iR7kxxp70sX4oNKkmY2m8de3gf8V+D+yUJV/avJ5SSfBL7b6f9MVa2bZj/3Au8HHqX3aMz19B5vuRXYV1Xbkmxt6x85t48hzWzN1i8PeggL6ui2dw96CPoRcNYzg6r6OnBqurb2v/tbgQfOtI8ky4E3V9X+9ljM+4FbWvMGYGdb3tmpS5IWSb/XDN4JnKiqI53a2iTfSvLnSd7ZaiuA8U6f8VYDWFZVx9vyC8CyPsckSTpHs5kmOpPb+OGzguPA6qp6McnVwJ8kuXK2O6uqSlIztSfZAmwBWL169RyHLEmaas5nBkkuAn4V+PxkrapeqaoX2/JjwDPA5cAxYGVn85WtBnCiTSNNTiednOmYVbW9qkaqamRoaGiuQ5ckTdHPNNG/BL5dVf9/+ifJUJIlbfmngWHg2TYN9HKSa9t1hk3AI22zXcDmtry5U5ckLZLZ3Fr6APC/gZ9NMp7k9ta0kddeOP4l4FC71fQLwAeravLi84eA/wGM0Ttj+EqrbwPeleQIvYDZ1sfnkSTNwVmvGVTVbTPUf32a2sPAwzP0HwWumqb+InD92cYhSVo4/gJZkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKY3ZPOdiQ5meSJTu1jSY4lOdheN3faPppkLMnTSW7s1Ne32liSrZ362iSPtvrnk1w8nx9QknR2szkzuA9YP039U1W1rr12AyS5gt7jMK9s2/y3JEvac5E/DdwEXAHc1voC/E7b188ALwG3Tz2QJGlhnTUMqurrwKmz9Ws2AA9W1StV9R16zzu+pr3GqurZqvo74EFgQ5IA/4Le85IBdgK3nONnkCT1qZ9rBncmOdSmkZa22grg+U6f8Vabqf6TwP+tqtNT6pKkRTTXMLgXeCuwDjgOfHLeRnQGSbYkGU0yOjExsRiHlKQLwpzCoKpOVNWrVfUD4DP0poEAjgGrOl1XttpM9ReBS5JcNKU+03G3V9VIVY0MDQ3NZeiSpGnMKQySLO+svgeYvNNoF7AxyRuSrAWGgW8AB4DhdufQxfQuMu+qqgK+Bvxa234z8MhcxiRJmruLztYhyQPAdcBlScaBu4DrkqwDCjgKfACgqg4neQh4EjgN3FFVr7b93AnsAZYAO6rqcDvER4AHk/wH4FvAZ+ft00mSZuWsYVBVt01TnvEf7Kq6G7h7mvpuYPc09Wf5h2kmSdIA+AtkSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEliFmGQZEeSk0me6NT+c5JvJzmU5ItJLmn1NUn+NsnB9vr9zjZXJ3k8yViSe5Kk1S9NsjfJkfa+dCE+qCRpZrM5M7gPWD+lthe4qqr+KfCXwEc7bc9U1br2+mCnfi/wfnrPRR7u7HMrsK+qhoF9bV2StIjOGgZV9XXg1JTan1bV6ba6H1h5pn0kWQ68uar2V1UB9wO3tOYNwM62vLNTlyQtkvm4ZvBvgK901tcm+VaSP0/yzlZbAYx3+oy3GsCyqjrell8Als3DmCRJ5+CifjZO8tvAaeBzrXQcWF1VLya5GviTJFfOdn9VVUnqDMfbAmwBWL169dwHLkn6IXM+M0jy68AvA/+6Tf1QVa9U1Ytt+THgGeBy4Bg/PJW0stUATrRppMnppJMzHbOqtlfVSFWNDA0NzXXokqQp5hQGSdYD/x74lar6fqc+lGRJW/5peheKn23TQC8nubbdRbQJeKRttgvY3JY3d+qSpEVy1mmiJA8A1wGXJRkH7qJ399AbgL3tDtH97c6hXwI+nuTvgR8AH6yqyYvPH6J3Z9Ib6V1jmLzOsA14KMntwHPArfPyySRJs3bWMKiq26Ypf3aGvg8DD8/QNgpcNU39ReD6s41DkrRw/AWyJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCQxyzBIsiPJySRPdGqXJtmb5Eh7X9rqSXJPkrEkh5K8vbPN5tb/SJLNnfrVSR5v29zTHo0pSVoksz0zuA9YP6W2FdhXVcPAvrYOcBO9Zx8PA1uAe6EXHvQemfkO4BrgrskAaX3e39lu6rEkSQtoVmFQVV8HTk0pbwB2tuWdwC2d+v3Vsx+4JMly4EZgb1WdqqqXgL3A+tb25qraX1UF3N/ZlyRpEfRzzWBZVR1vyy8Ay9ryCuD5Tr/xVjtTfXyauiRpkczLBeT2P/qaj32dSZItSUaTjE5MTCz04STpgtFPGJxoUzy095OtfgxY1em3stXOVF85Tf01qmp7VY1U1cjQ0FAfQ5ckdfUTBruAyTuCNgOPdOqb2l1F1wLfbdNJe4AbkixtF45vAPa0tpeTXNvuItrU2ZckaRFcNJtOSR4ArgMuSzJO766gbcBDSW4HngNubd13AzcDY8D3gfcBVNWpJJ8ADrR+H6+qyYvSH6J3x9Ibga+0lyRpkcwqDKrqthmarp+mbwF3zLCfHcCOaeqjwFWzGYskaf75C2RJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCTRRxgk+dkkBzuvl5N8OMnHkhzr1G/ubPPRJGNJnk5yY6e+vtXGkmzt90NJks7NrB57OZ2qehpYB5BkCXAM+CK9Zx5/qqp+t9s/yRXARuBK4C3AnyW5vDV/GngXMA4cSLKrqp6c69gkSedmzmEwxfXAM1X1XJKZ+mwAHqyqV4DvJBkDrmltY1X1LECSB1tfw0CSFsl8XTPYCDzQWb8zyaEkO5IsbbUVwPOdPuOtNlP9NZJsSTKaZHRiYmKehi5J6jsMklwM/ArwR610L/BWelNIx4FP9nuMSVW1vapGqmpkaGhovnYrSRe8+Zgmugn4ZlWdAJh8B0jyGeBLbfUYsKqz3cpW4wx1SdIimI9potvoTBElWd5pew/wRFveBWxM8oYka4Fh4BvAAWA4ydp2lrGx9ZUkLZK+zgyS/AS9u4A+0Cn/pyTrgAKOTrZV1eEkD9G7MHwauKOqXm37uRPYAywBdlTV4X7GJelHx5qtXx70EBbU0W3vHvQQgD7DoKr+BvjJKbX3nqH/3cDd09R3A7v7GYskae78BbIkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJDEPYZDkaJLHkxxMMtpqlybZm+RIe1/a6klyT5KxJIeSvL2zn82t/5Ekm/sdlyRp9ubrzOCfV9W6qhpp61uBfVU1DOxr6wA30Xv28TCwBbgXeuEB3AW8A7gGuGsyQCRJC2+hpok2ADvb8k7glk79/urZD1ySZDlwI7C3qk5V1UvAXmD9Ao1NkjTFfIRBAX+a5LEkW1ptWVUdb8svAMva8grg+c624602U/2HJNmSZDTJ6MTExDwMXZIEcNE87OMXq+pYkn8M7E3y7W5jVVWSmofjUFXbge0AIyMj87JPSdI8nBlU1bH2fhL4Ir05/xNt+of2frJ1Pwas6my+stVmqkuSFkFfYZDkJ5L8o8ll4AbgCWAXMHlH0Gbgkba8C9jU7iq6Fvhum07aA9yQZGm7cHxDq0mSFkG/00TLgC8mmdzXH1bVV5McAB5KcjvwHHBr678buBkYA74PvA+gqk4l+QRwoPX7eFWd6nNskqRZ6isMqupZ4J9NU38RuH6aegF3zLCvHcCOfsYjSZobf4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEn0EQZJViX5WpInkxxO8hut/rEkx5IcbK+bO9t8NMlYkqeT3Nipr2+1sSRb+/tIkqRz1c+Tzk4Dv1lV32zPQX4syd7W9qmq+t1u5yRXABuBK4G3AH+W5PLW/GngXcA4cCDJrqp6so+xSZLOwZzDoD3I/nhb/uskTwErzrDJBuDBqnoF+E6SMeCa1jbWHqFJkgdbX8NAkhbJvFwzSLIGeBvwaCvdmeRQkh1JlrbaCuD5zmbjrTZTfbrjbEkymmR0YmJiPoYuSWIewiDJm4CHgQ9X1cvAvcBbgXX0zhw+2e8xJlXV9qoaqaqRoaGh+dqtJF3w+rlmQJIfpxcEn6uqPwaoqhOd9s8AX2qrx4BVnc1XthpnqEuSFkE/dxMF+CzwVFX9Xqe+vNPtPcATbXkXsDHJG5KsBYaBbwAHgOEka5NcTO8i8665jkuSdO76OTP4BeC9wONJDrbabwG3JVkHFHAU+ABAVR1O8hC9C8OngTuq6lWAJHcCe4AlwI6qOtzHuCRJ56ifu4n+Asg0TbvPsM3dwN3T1HefaTtJ0sLyF8iSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAksR5FAZJ1id5OslYkq2DHo8kXUjOizBIsgT4NHATcAW9R2deMdhRSdKF47wIA+AaYKyqnq2qvwMeBDYMeEySdMGY8zOQ59kK4PnO+jjwjqmdkmwBtrTV7yV5ehHGNiiXAX+1WAfL7yzWkS4Ifnevbz/q399PTVc8X8JgVqpqO7B90ONYDElGq2pk0OPQufO7e327UL+/82Wa6BiwqrO+stUkSYvgfAmDA8BwkrVJLgY2ArsGPCZJumCcF9NEVXU6yZ3AHmAJsKOqDg94WIN2QUyH/Yjyu3t9uyC/v1TVoMcgSRqw82WaSJI0QIaBJMkwkCSdJxeQpdezJD9H74eTj1bV9zr19VX11cGNTGfTvrsN9L4/6N3SvquqnhrcqAbDM4PzXJL3DXoMmlmSfwc8Avxb4Ikk3T+j8h8HMyrNRpKP0PvTNwG+0V4BHrgQ/1imdxOd55L8n6paPehxaHpJHgd+vqq+l2QN8AXgD6rqvyT5VlW9baAD1IyS/CVwZVX9/ZT6xcDhqhoezMgGw2mi80CSQzM1AcsWcyw6Zz82OTVUVUeTXAd8IclP0fv+dP76AfAW4Lkp9eWt7YJiGJwflgE3Ai9NqQf4X4s/HJ2DE0nWVdVBgHaG8MvADuCfDHZoOosPA/uSHOEf/lDmauBngDsHNqoBMQzOD18C3jT5D0pXkv+5+MPROdgEnO4Wquo0sCnJfx/MkDQbVfXVJJfT+xP63QvIB6rq1cGNbDC8ZiBJ8m4iSZJhIEnCMJAkYRhIkjAMJEnA/wO1E4/woNcIIAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOJKrrwMC60P"
      },
      "source": [
        "Repeating the preprocessing steps I took earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBghfl1_C7sZ"
      },
      "source": [
        "# Apply preprocess function to the 'text' column to generate a new column called 'Processed text'.\r\n",
        "sentiment_train['Processed_Text'] = sentiment_train['text'].apply(preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UBD03zOFaYR"
      },
      "source": [
        "# Apply getAdjectives function to the new 'Processed Tweets' column to generate a new column called 'Tweets_Adjectives'\r\n",
        "sentiment_train['Text_Adjectives'] = sentiment_train['Processed_Text'].apply(getAdjectives)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuZfWheSFc09"
      },
      "source": [
        "# Apply preprocessTweetsSentiments function to the 'Processed Tweets' column to generate a new column\r\n",
        "# called 'Processed_Tweets'\r\n",
        "sentiment_train['Text_Sentiments'] = sentiment_train['Processed_Text'].apply(preprocessTweetsSentiments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQeXR74NFwr6"
      },
      "source": [
        "#printing results for better analysis\r\n",
        "print(sentiment_train['text'][19])\r\n",
        "print(sentiment_train['Processed_Text'][19])\r\n",
        "print(sentiment_train['Text_Sentiments'][19])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEHEmoRGKrGr"
      },
      "source": [
        "##3) Exploratory Data Analysis\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXEpqZdkn7XN"
      },
      "source": [
        "Here, we will explore our data. To do this, we will identify the most common words in each classification task. In this section, we will; \r\n",
        "*   Identify the most common words in our data\r\n",
        "*   Perform sentiment analysis\r\n",
        "word frequency analysis,\r\n",
        "sentence length analysis,\r\n",
        "average word length analysis,\r\n",
        "*   Target Distribution\r\n",
        "*   List item\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOGhwoavWojB"
      },
      "source": [
        "#####Defining functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGZJ-6UfWoIH"
      },
      "source": [
        "#Function gets the most common words and displays them\r\n",
        "def show_wordcloud(data):\r\n",
        "    wordcloud = WordCloud(\r\n",
        "        background_color='white',\r\n",
        "        stopwords=stopwords,\r\n",
        "        max_words=100,\r\n",
        "        max_font_size=30,\r\n",
        "        scale=3,\r\n",
        "        random_state=1)\r\n",
        "   \r\n",
        "    wordcloud=wordcloud.generate(str(data))\r\n",
        "\r\n",
        "    fig = plt.figure(1, figsize=(12, 12))\r\n",
        "    plt.axis('off')\r\n",
        "\r\n",
        "    plt.imshow(wordcloud)\r\n",
        "    plt.show()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1zfB7ccW4Z4"
      },
      "source": [
        "show_wordcloud(emotion_train[Processed_Text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhI755LmYQhb"
      },
      "source": [
        "# Extract all tweets into one long string with each word separate with a \"space\"\r\n",
        "tweets_long_string = emotion_train['Tweets_Adjectives'].tolist()\r\n",
        "tweets_long_string = \" \".join(tweets_long_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXHvkYNtYlRh"
      },
      "source": [
        "# Create function to generate the blue colour for the Word CLoud\r\n",
        "\r\n",
        "def blue_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\r\n",
        "    return \"hsl(210, 100%%, %d%%)\" % random.randint(50, 70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfE2Ha07YtUZ"
      },
      "source": [
        "# Import Twitter Logo\r\n",
        "image = np.array(Image.open('/content/twitter_PNG1.png'))\r\n",
        "    \r\n",
        "fig = plt.figure() # Instantiate the figure object\r\n",
        "fig.set_figwidth(14) # set width\r\n",
        "fig.set_figheight(18) # set height\r\n",
        "\r\n",
        "#plt.imshow(image, cmap=plt.cm.gray, interpolation='bilinear') # Display data as an image\r\n",
        "plt.axis('off') # Remove axis\r\n",
        "plt.show() # Display image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MkLsn0OYebx"
      },
      "source": [
        "# Instantiate the Twitter word cloud object\r\n",
        "twitter_wc = WordCloud(background_color='white', max_words=1500, mask=image)\r\n",
        "\r\n",
        "# generate the word cloud\r\n",
        "twitter_wc.generate(tweets_long_string)\r\n",
        "\r\n",
        "# display the word cloud\r\n",
        "fig = plt.figure()\r\n",
        "fig.set_figwidth(14)  # set width\r\n",
        "fig.set_figheight(18)  # set height\r\n",
        "\r\n",
        "plt.imshow(twitter_wc.recolor(color_func=blue_color_func, random_state=3),\r\n",
        "           interpolation=\"bilinear\")\r\n",
        "plt.axis('off')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h44f0sjmWHFh"
      },
      "source": [
        "######EDA on emotion dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtM6yBlZMazq"
      },
      "source": [
        "emotion_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxr1tR2wgUEO"
      },
      "source": [
        "Great, no missing values in the  texts! Do we have class imbalance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcHoVUo2JkIb"
      },
      "source": [
        "emotion_train['Mapping'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CigBJShtRof8"
      },
      "source": [
        "This plot shows a huge imbalance with the most tweet showing angry emotions, and very few data on optimisim. We will have to work on balancing the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ey0ir8uGteC"
      },
      "source": [
        "######EDA on irony dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHTkXGogGtee"
      },
      "source": [
        "irony_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_veRFCTxGteg"
      },
      "source": [
        "#pie chart analysis of my data \r\n",
        "irony_train.groupby(['Mapping']).sum().plot(kind='pie', subplots=True, shadow = True,startangle=90,\r\n",
        "figsize=(15,10), autopct='%1.1f%%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piny4g27GwJ1"
      },
      "source": [
        "######EDA on sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faQQATUyGwJ2"
      },
      "source": [
        "sentiment_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jePmyHBCJAuP"
      },
      "source": [
        "#pie chart analysis of my data \r\n",
        "sentiment_train.groupby(['Mapping']).sum().plot(kind='pie', subplots=True, shadow = True,startangle=90,\r\n",
        "figsize=(15,10), autopct='%1.1f%%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OhZKUwkGwJ3"
      },
      "source": [
        "Let‚Äôs take a look at the inferences drawn from the above analysis:\r\n",
        "From my analysis, we can see how the data stats. With wordcloud, we can see the most common words. \r\n",
        "We can also see that there are some imbalances in our emotion and sentiment dataset. This could cause some bias when training our model, so we will need to deal with them before training a model on them. \r\n",
        "\r\n",
        "We can delve further to find the most common words for each label of each task. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T5Im2b3Ofss"
      },
      "source": [
        "####Reference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmLFCCiTUpvf"
      },
      "source": [
        "# Citing TweetEval datasets\r\n",
        "\r\n",
        "If you use any of the TweetEval datasets, please cite their original publications:\r\n",
        "\r\n",
        "#### Emotion Recognition:\r\n",
        "```\r\n",
        "@inproceedings{mohammad2018semeval,\r\n",
        "  title={Semeval-2018 task 1: Affect in tweets},\r\n",
        "  author={Mohammad, Saif and Bravo-Marquez, Felipe and Salameh, Mohammad and Kiritchenko, Svetlana},\r\n",
        "  booktitle={Proceedings of the 12th international workshop on semantic evaluation},\r\n",
        "  pages={1--17},\r\n",
        "  year={2018}\r\n",
        "}\r\n",
        "\r\n",
        "```\r\n",
        "\r\n",
        "#### Irony Detection:\r\n",
        "```\r\n",
        "@inproceedings{van2018semeval,\r\n",
        "  title={Semeval-2018 task 3: Irony detection in english tweets},\r\n",
        "  author={Van Hee, Cynthia and Lefever, Els and Hoste, V{\\'e}ronique},\r\n",
        "  booktitle={Proceedings of The 12th International Workshop on Semantic Evaluation},\r\n",
        "  pages={39--50},\r\n",
        "  year={2018}\r\n",
        "}\r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        "#### Sentiment Analysis:\r\n",
        "```\r\n",
        "@inproceedings{rosenthal2017semeval,\r\n",
        "  title={SemEval-2017 task 4: Sentiment analysis in Twitter},\r\n",
        "  author={Rosenthal, Sara and Farra, Noura and Nakov, Preslav},\r\n",
        "  booktitle={Proceedings of the 11th international workshop on semantic evaluation (SemEval-2017)},\r\n",
        "  pages={502--518},\r\n",
        "  year={2017}\r\n",
        "}\r\n",
        "```"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqndgj8ROjAh"
      },
      "source": [
        "[Analyzing Twitter Users' Reflections using NLP](https://nbviewer.jupyter.org/github/jess-data/Twitter-2020-Sentiment-Analysis/blob/master/Twitter%20Sentiment%20Analysis%20Project.ipynb)\r\n",
        "\r\n",
        "[Sentiment-analysis-with-bert](https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S#scrollTo=U3HZb3NWFtFf)\r\n",
        "\r\n",
        "[A Beginner‚Äôs Guide to Exploratory Data Analysis (EDA) on Text Data (Amazon Case Study)](https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/)\r\n",
        "\r\n",
        "[Exploratory Data Analysis for Natural Language Processing: A Complete Guide to Python Tools](https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools)"
      ]
    }
  ]
}